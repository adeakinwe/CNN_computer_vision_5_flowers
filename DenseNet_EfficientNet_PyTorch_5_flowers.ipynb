{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adeakinwe/computer_vision/blob/main/DenseNet_EfficientNet_PyTorch_5_flowers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekVzSW8Bb_Ze",
        "outputId": "c4dfa6a1-2fe4-4695-e612-d5fac0cb4a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HUjjD6MRYJmr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "import wandb\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zxVl69yfYLO3"
      },
      "outputs": [],
      "source": [
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ti4rs4tkYMos"
      },
      "outputs": [],
      "source": [
        "# =======================\n",
        "# STEP 1: Data Preparation\n",
        "# =======================\n",
        "\n",
        "# Transforms for training and validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "train_dir = \"/content/drive/MyDrive/5flowersdata/flowers/train\"\n",
        "val_dir = \"/content/drive/MyDrive/5flowersdata/flowers/val\"\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=data_transforms['train'])\n",
        "val_dataset = datasets.ImageFolder(root=val_dir, transform=data_transforms['val'])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Uu1_CDgvYOEW"
      },
      "outputs": [],
      "source": [
        "# Training Function\n",
        "def train_model(model, model_name):\n",
        "    wandb.init(project=f\"{model_name}-flowers\", config={\n",
        "        \"epochs\": 10,\n",
        "        \"batch_size\": 16,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"architecture\": model_name,\n",
        "        \"pretrained\": True\n",
        "    })\n",
        "    config = wandb.config\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config.learning_rate)\n",
        "    wandb.watch(model, log=\"all\", log_freq=10)\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_acc = correct / total\n",
        "        wandb.log({\"train_loss\": train_loss, \"train_accuracy\": train_acc})\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "        val_acc = val_correct / val_total\n",
        "        wandb.log({\"val_accuracy\": val_acc})\n",
        "        print(f\"Epoch {epoch+1} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mxiVbXfxYPiW"
      },
      "outputs": [],
      "source": [
        "# Model setup functions\n",
        "def get_efficientnet():\n",
        "    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, 5)\n",
        "    for param in model.parameters(): param.requires_grad = False\n",
        "    for param in model.classifier[1].parameters(): param.requires_grad = True\n",
        "    return model\n",
        "\n",
        "def get_densenet():\n",
        "    model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
        "    model.classifier = nn.Linear(model.classifier.in_features, 5)\n",
        "    for param in model.parameters(): param.requires_grad = False\n",
        "    for param in model.classifier.parameters(): param.requires_grad = True\n",
        "    return model\n",
        "\n",
        "def get_xception():\n",
        "    from timm import create_model\n",
        "    model = create_model('xception', pretrained=True, num_classes=5)\n",
        "    for param in model.parameters(): param.requires_grad = False\n",
        "    for param in model.get_classifier().parameters(): param.requires_grad = True\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "_g-opvZQESck",
        "outputId": "46fee832-19b7-4f10-a13d-5fb81b23a130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 135MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madeakinwe\u001b[0m (\u001b[33madeakinwe-richkinwe-io\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250809_122453-a1vcw1bb</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/adeakinwe-richkinwe-io/DenseNet-flowers/runs/a1vcw1bb' target=\"_blank\">fallen-field-2</a></strong> to <a href='https://wandb.ai/adeakinwe-richkinwe-io/DenseNet-flowers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/adeakinwe-richkinwe-io/DenseNet-flowers' target=\"_blank\">https://wandb.ai/adeakinwe-richkinwe-io/DenseNet-flowers</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/adeakinwe-richkinwe-io/DenseNet-flowers/runs/a1vcw1bb' target=\"_blank\">https://wandb.ai/adeakinwe-richkinwe-io/DenseNet-flowers/runs/a1vcw1bb</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Main loop\n",
        "model_dict = {\n",
        "    #\"EfficientNet\": get_efficientnet,\n",
        "    \"DenseNet\": get_densenet,\n",
        "    #\"Xception\": get_xception\n",
        "}\n",
        "\n",
        "for name, get_model in model_dict.items():\n",
        "    model = get_model()\n",
        "    train_model(model, name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}